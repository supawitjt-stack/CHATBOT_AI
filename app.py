import os
import streamlit as st
import google.generativeai as genai
import fitz  # PyMuPDF
import easyocr #pytorch
import numpy as np
from PIL import Image
import torch
import dotenv
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Prompt (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå prompt.py ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
try:
    from prompt import PROMPT_C_Programmer
except ImportError:
    # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏ì‡∏µ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ Default
    PROMPT_C_Programmer = "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏≤ C ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç ‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£"

# --- 1. Configuration & Setup ---
dotenv.load_dotenv()
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')

st.set_page_config(
    page_title="Chat Bot : C Programming AI",
    page_icon="ü§ñ",
    layout="wide", # ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô Wide mode ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡πá‡∏°‡∏à‡∏≠
    initial_sidebar_state="expanded"
)

# --- 2. Custom CSS (GUI Redesign: Vivid, Modern & Friendly) ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Kanit:wght@300;400;600;800&display=swap');

    /* Global Font Settings */
    html, body, [class*="css"] {
        font-family: 'Kanit', sans-serif;
    }

    /* Main Background Decoration (Optional: Gradient hint at top) */
    .stApp {
        background-image: linear-gradient(to bottom, #fdfbfb 0%, #ebedee 100%);
    }

    /* Header Styling: Gradient Text & Modern Look */
    .main-header {
        background: linear-gradient(90deg, #FF0080 0%, #7928CA 50%, #FF0080 100%);
        background-size: 200% auto;
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        animation: gradient 3s linear infinite;
        font-weight: 800;
        text-align: center;
        font-size: 3.5rem;
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    
    .sub-header {
        text-align: center;
        color: #555;
        font-size: 1.2rem;
        margin-bottom: 2rem;
    }

    /* Animation Keyframes */
    @keyframes gradient {
        0% { background-position: 0% center; }
        100% { background-position: 200% center; }
    }

    /* Chat Container Styling */
    .stChatMessage {
        background-color: white;
        border-radius: 20px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        margin-bottom: 15px;
        transition: transform 0.2s;
    }
    
    .stChatMessage:hover {
        transform: translateY(-2px);
    }

    /* User Avatar & Message */
    [data-testid="stChatMessage"][data-testid="stChatMessageUser"] {
        background: linear-gradient(135deg, #e0c3fc 0%, #8ec5fc 100%);
    }

    /* Bot Avatar & Message */
    [data-testid="stChatMessage"][data-testid="stChatMessageModel"] {
        background: white;
        border: 1px solid #eee;
    }

    /* Input Field Styling */
    .stChatInputContainer {
        border-radius: 30px;
        border: 2px solid #7928CA;
        padding: 5px;
    }

    /* Sidebar Styling */
    [data-testid="stSidebar"] {
        background-color: #f8f9fa;
        border-right: 1px solid #eee;
    }
    
    .sidebar-btn {
        width: 100%;
        border-radius: 10px;
        font-weight: 600;
    }

    .welcome-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 40px;
        border-radius: 25px;
        text-align: center;
        margin-bottom: 30px;
        box-shadow: 0 10px 30px rgba(118, 75, 162, 0.3);
    }
    .welcome-card h2 {
        color: white;
        font-weight: 700;
    }

    /* ----------------------------------------------------------- */
    /* ‚ú® MODERN CHAT INPUT REDESIGN (‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà)       */
    /* ----------------------------------------------------------- */
    
    /* ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÇ‡∏ã‡∏ô‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (Gradient Fade Out) */
    .stChatInputContainer {
        padding-bottom: 30px;
        padding-top: 15px;
        background: linear-gradient(to top, #ebedee 0%, rgba(255,255,255,0.8) 50%, rgba(255,255,255,0) 100%);
    }
    
    .main .block-container {
        padding-bottom: 140px; 
    }
    
    /* Input Textarea Styling */
    .stChatInputContainer textarea {
        background-color: #ffffff !important;
        color: #333 !important;
        
        /* ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏≥‡∏Ç‡∏≠‡∏ö Gradient */
        border: 2px solid transparent !important;
        border-radius: 35px !important;
        background-image: linear-gradient(white, white), linear-gradient(to right, #FF0080, #7928CA);
        background-origin: border-box;
        background-clip: padding-box, border-box;
        
        box-shadow: 0 8px 20px rgba(0,0,0,0.08) !important;
        transition: all 0.3s ease !important;
        font-size: 16px !important;
        padding: 15px 25px !important;
    }

    /* Effect ‡∏ï‡∏≠‡∏ô‡∏Å‡∏î‡∏û‡∏¥‡∏°‡∏û‡πå */
    .stChatInputContainer textarea:focus {
        box-shadow: 0 12px 25px rgba(121, 40, 202, 0.25) !important;
        transform: translateY(-3px);
    }
    
    /* ‡∏õ‡∏∏‡πà‡∏° Send (Icon) */
    .stChatInputContainer button {
        background: linear-gradient(135deg, #FF0080 0%, #7928CA 100%) !important;
        border: none !important;
        border-radius: 50% !important;
        width: 45px !important;
        height: 45px !important;
        color: white !important;
        box-shadow: 0 4px 10px rgba(121, 40, 202, 0.3) !important;
        margin-right: 5px !important;
        transition: all 0.2s cubic-bezier(0.175, 0.885, 0.32, 1.275) !important; 
    }
    
    .stChatInputContainer button:hover {
        transform: scale(1.15);
        box-shadow: 0 6px 15px rgba(121, 40, 202, 0.5) !important;
    }
    
    .stChatInputContainer button svg {
        fill: white !important;
        width: 20px !important;
        height: 20px !important;
    }    
            
    /* Hide Default Menus */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# --- 3. Gemini Configuration ---
if not GOOGLE_API_KEY:
    st.error("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GOOGLE_API_KEY ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå .env")
    st.stop()

genai.configure(api_key=GOOGLE_API_KEY)
generation_config = {
    "temperature": 0.1, 
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 2048,
    "response_mime_type": "text/plain",
}
SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE
}
model = genai.GenerativeModel(
    model_name="gemini-2.5-flash", 
    generation_config=generation_config,
    system_instruction=PROMPT_C_Programmer
)

# --- 4. Smart OCR & Data Handling (‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏°) ---
CACHE_FILENAME = "extracted_content_cache.txt"
PDF_FILE_PATH = r"D:\KMUTNB\Vatinee Nuipian\Project_AI_CHATBOT\CHATBOT_AI\PROGRAMMING_C.pdf"

@st.cache_resource
def load_ocr_model():
    use_gpu = torch.cuda.is_available()
    return easyocr.Reader(['th', 'en'], gpu=use_gpu)

def get_knowledge_base():
    # ‡∏Å‡∏£‡∏ì‡∏µ 1: ‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå Cache ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏¢
    if os.path.exists(CACHE_FILENAME):
        with open(CACHE_FILENAME, "r", encoding="utf-8") as f:
            return f.read()

    # ‡∏Å‡∏£‡∏ì‡∏µ 2: ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ OCR
    if not os.path.exists(PDF_FILE_PATH):
        return None 

    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ OCR
    status_placeholder = st.empty()
    progress_bar = st.progress(0)
    status_placeholder.info("üìë ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á‡∏Ñ‡∏£‡∏±‡∏ö)...")

    progress_bar = st.progress(0, text="Starting engine...")
    try:
        reader = load_ocr_model()
        doc = fitz.open(PDF_FILE_PATH)
        full_text = []
        
        start_page = 13
        end_page = 173
        pages_to_process = [p for p in range(len(doc)) if start_page <= p + 1 <= end_page]
        total_target_pages = len(pages_to_process)

        processed_count = 0

        for page_index in pages_to_process:
            current_page_num = page_index + 1
            processed_count += 1
            percent = int((processed_count / total_target_pages) * 100)
            progress_bar.progress(min(percent, 100), text=f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {current_page_num} ({percent}%)")

            page = doc[page_index]
            pix = page.get_pixmap(matrix=fitz.Matrix(3, 3))
            img = np.array(Image.frombytes("RGB", [pix.width, pix.height], pix.samples))

            result = reader.readtext(img, detail=0)
            page_content = " ".join(result)
            full_text.append(f"--- Page {current_page_num} ---\n{page_content}")

        combined_text = "\n".join(full_text)
        
        with open(CACHE_FILENAME, "w", encoding="utf-8") as f:
            f.write(combined_text)
        
        status_placeholder.empty()
        progress_bar.empty()
        st.toast("‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏•‡∏∏‡∏¢!", icon="üöÄ")
        return combined_text

    except Exception as e:
        status_placeholder.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        return None

# --- 5. UI Logic & Layout ---

# Initialize Session State
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "model", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏ã‡∏µ‡∏¢‡∏ô C ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏Ñ‡∏£‡∏±‡∏ö ‡∏°‡∏µ‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏†‡∏≤‡∏©‡∏≤ C ‡∏ï‡∏£‡∏á‡πÑ‡∏´‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Ç‡∏±‡∏î ‡∏ñ‡∏≤‡∏°‡∏ú‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö üöÄ"}
    ]

# Sidebar (Modernized)
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/4712/4712035.png", width=100) # Placeholder Icon
    st.markdown("### ‚öôÔ∏è ‡πÄ‡∏°‡∏ô‡∏π‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á")
    
    st.markdown("---")
    if st.button("üóëÔ∏è ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà", use_container_width=True, type="primary"):
        st.session_state["messages"] = [
            {"role": "model", "content": "‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢! ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏Ñ‡∏£‡∏±‡∏ö ‚ú®"}
        ]
        st.rerun()
    
    st.markdown("---")
    st.info("üí° **Tip:** ‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏†‡∏≤‡∏©‡∏≤ C ‡∏î‡∏π‡∏™‡∏¥‡∏Ñ‡∏£‡∏±‡∏ö")
    st.caption("Developed By Mr.Thanaphon & Mr.Supawit SMTCT68")

# Main Content Structure
col1, col2, col3 = st.columns([1, 6, 1]) # ‡∏à‡∏±‡∏î Layout ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°
with col2:
    st.markdown("<h1 class='main-header'>::: ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏ã‡∏µ‡∏¢‡∏ô C Programming :::</h1>", unsafe_allow_html=True)
    st.markdown("<div class='sub-header'>‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏π‡πà‡∏Ñ‡∏¥‡∏î ‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏†‡∏≤‡∏©‡∏≤ C (AI Chatbot)</div>", unsafe_allow_html=True)

    # Load Content (Background)
    if "knowledge_base" not in st.session_state:
        with st.spinner("üì¶ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ..."):
            kb_text = get_knowledge_base()
            if kb_text:
                st.session_state["knowledge_base"] = kb_text
            else:
                st.error("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

    # Welcome Screen Logic (‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏±‡∏á)
    if len(st.session_state["messages"]) <= 1:
        st.markdown("""
        <div class='welcome-card'>
            <h2>üëã ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà‡∏´‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏†‡∏≤‡∏©‡∏≤ C</h2>
            <p>‡∏ú‡∏°‡∏Ñ‡∏∑‡∏≠ ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏ã‡∏µ‡∏¢‡∏ô C AI Assistant ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ù‡∏∂‡∏Å‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°</p>
            <p style='font-size: 0.9rem; opacity: 0.8;'>‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô "‡∏™‡∏≠‡∏ô For Loop ‡∏´‡∏ô‡πà‡∏≠‡∏¢", "‡∏Ç‡∏≠‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á ‡πÜ"</p>
        </div>
        """, unsafe_allow_html=True)

    # Display Chat
    for msg in st.session_state["messages"]:
        if msg["role"] == "model":
            avatar = "ü§ñ"
        else:
            avatar = "üßë‚Äçüíª"
            
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

    # Chat Input & Processing
    if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà..."):
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
        st.session_state["messages"].append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üßë‚Äçüíª"):
            st.markdown(prompt)

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
        with st.chat_message("model", avatar="ü§ñ"):
            message_placeholder = st.empty()
            message_placeholder.markdown("‚è≥ _‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..._")

            try:
                # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Context
                kb_content = st.session_state.get("knowledge_base", "")
                
                if kb_content:
                    # --- ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Prompt ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î‡∏Ç‡∏∂‡πâ‡∏ô (STRICT MODE) ---
                    final_prompt = f"""
                    ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏≤ C  ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ" (Context) ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

                    === ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ (Context) ===
                    {kb_content}
                    ===================================

                    ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: {prompt}

                    ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ (Strict Instructions):
                    1. ‡πÉ‡∏´‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ" ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î
                    2. ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏∞‡∏ö‡∏∏‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ" ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ß‡πà‡∏≤ "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏ã‡∏µ‡∏¢‡∏ô  C ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏°‡∏≤‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö" (‡∏´‡πâ‡∏≤‡∏°‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏≠‡∏á)
                    3. ‡∏´‡∏≤‡∏Å‡πÉ‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏ï‡πà‡∏Ñ‡∏á Code ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏¥‡∏°
                    4. ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤ C ‡∏´‡∏£‡∏∑‡∏≠ Programming ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
                    """
                    response = model.generate_content(final_prompt)
                    answer = response.text
                else:
                    answer = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏ã‡∏µ‡∏¢‡∏ô C ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏°‡∏≤‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö "
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                message_placeholder.markdown(answer)
                st.session_state["messages"].append({"role": "model", "content": answer})

            except Exception as e:
                message_placeholder.error("‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö AI")
                print(f"Error: {e}")